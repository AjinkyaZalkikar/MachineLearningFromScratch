{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhHFbSUw5M59"
      },
      "source": [
        "# CSCE 633 :: Machine Learning :: Texas A&M University :: Spring 2022\n",
        "\n",
        "# Programming Assignment 2 (PA 2)\n",
        "**Name:**  Ajinkya Zalkikar\n",
        "**UIN:**   530005943"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gqxpkg4m5M6B"
      },
      "source": [
        "# Linear and Logistic Regression\n",
        "- **100 points**\n",
        "- **Due Tuesday, March 15, 11:59 pm**\n",
        "\n",
        "In this assignment, you'll be coding up linear and logistic regression algorithms from scratch. \n",
        "\n",
        "### Instructions\n",
        "- You are **NOT** allowed to use machine learning libraries such as `scikit-learn` to build the models for this assignment.\n",
        "- You are required to complete the functions defined in the code blocks following each question. Fill out sections of the code marked `\"YOUR CODE HERE\"`.\n",
        "- You're free to add any number of methods within each class.\n",
        "- You may also add any number of additional code blocks that you deem necessary. \n",
        "- Once you've filled out your solutions, submit the notebook on Canvas following the instructions [here](https://people.engr.tamu.edu/guni/csce421/assignments.html).\n",
        "- Do **NOT** forget to type in your name and UIN at the beginning of the notebook.\n",
        "- Do **NOT** remove any code provided."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5DkFktt5M6C"
      },
      "source": [
        "## Question 1 (50 points)\n",
        "\n",
        "## Linear Regression\n",
        "\n",
        "In this section, we'll implement a linear regression model that can learn to predict a target/dependent variable based on multiple independent variables. We'll be using gradient descent to train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CwXJhEx65M6D"
      },
      "outputs": [],
      "source": [
        "# Importing Libraries\n",
        "import time\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otIXk9ST5M6E"
      },
      "source": [
        "### Data Preparation.\n",
        "To keep things simple, first we'll use a toy dataset to test our implementation. This dataset contains the heights and weights of a few individuals. Our goal is to predict the weight of an individual given their height using a linear regression model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "k151_Knh5M6F"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('http://people.tamu.edu/~sumedhpendurkar/csce633/heights_weights.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YEuVPUKN5M6F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "157eb172-78f6-4ebf-e5ce-8a909e2070f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Height  Weight\n",
              "0    1.47   52.21\n",
              "1    1.50   53.12\n",
              "2    1.52   54.48\n",
              "3    1.55   55.84\n",
              "4    1.57   57.20"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8a3c3e34-69a7-4cb7-a857-266eed71ff79\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.47</td>\n",
              "      <td>52.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.50</td>\n",
              "      <td>53.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.52</td>\n",
              "      <td>54.48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.55</td>\n",
              "      <td>55.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.57</td>\n",
              "      <td>57.20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8a3c3e34-69a7-4cb7-a857-266eed71ff79')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8a3c3e34-69a7-4cb7-a857-266eed71ff79 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8a3c3e34-69a7-4cb7-a857-266eed71ff79');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_4jFzzrG5M6G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "4c077871-3e38-4ec0-e369-e78499f4caea"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(df['Height'], df['Weight'], marker='X')\n",
        "plt.xlabel(\"Height\")\n",
        "plt.ylabel(\"Weight\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymMskKzY5M6G"
      },
      "source": [
        "Looking at the distribution of the data, it seems like `Weight` and `Height` have a linear relationship. Hence, a linear regression model should be able to capture this relationship.  \n",
        "\n",
        "Let's us convert the dataframe `df` to a Numpy array so that it is easier to perform operations on it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1y6sGMyJ5M6H"
      },
      "outputs": [],
      "source": [
        "X_train = np.array(df['Height'])\n",
        "y_train = np.array(df['Weight'])\n",
        "X_train = np.expand_dims(X_train, -1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7znTXa-5M6H"
      },
      "source": [
        "### (30 points) Implement the ` LinearRegression` class\n",
        "Make sure it works with more than 1 feature.\n",
        "\n",
        "**NOTE:** Do **NOT** forget to include a bias term in the weights. \n",
        "\n",
        "**NOTE:** You can initialize weights and bias to 0.\n",
        "\n",
        "**NOTE:** Do **NOT** use closed form solutions. Use gradient descent to update weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "StGUs-OW5M6I"
      },
      "outputs": [],
      "source": [
        "class LinearRegression:   \n",
        "    def __init__(self, lr=0.001, epochs=30):\n",
        "        \"\"\"\n",
        "        Fits a linear regression model on a given dataset.\n",
        "        \n",
        "        Args:\n",
        "            lr: learning rate \n",
        "            epochs: number of iterations over the dataset \n",
        "        \"\"\"\n",
        "        self.lr = lr  \n",
        "        self.epochs = epochs\n",
        "        self.wt = [55 for i in range(X_train.shape[1])]\n",
        "             \n",
        "                \n",
        "    def train(self, X, y):\n",
        "      for i in range(self.epochs):\n",
        "        self.update_weights(X, y)\n",
        "        \"\"\"\n",
        "        Initialize weights. Iterate through the dataset and update weights once every epoch.\n",
        "        \n",
        "        Args:\n",
        "            X: features\n",
        "            y: target\n",
        "        \"\"\"\n",
        "        for i in range(self.epochs):\n",
        "          self.update_weights(X, y)\n",
        "        \n",
        "        \n",
        "        \n",
        "         \n",
        "    def update_weights(self, X, y):\n",
        "        \"\"\"\n",
        "        Helper function to calculate the gradients and update weights using batch gradient descent.\n",
        "        \n",
        "        Args:\n",
        "            X: features\n",
        "            y: target\n",
        "        \"\"\"\n",
        "        AZ = np.dot(X.transpose(), (y - np.dot(self.wt, X.transpose())).transpose())\n",
        "        AAZ = -1 * 2 * AZ / X.shape[0]\n",
        "        self.wt -= self.lr * AAZ\n",
        "        \n",
        "     \n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predict values using the weights.\n",
        "        \n",
        "        Args:\n",
        "            X: features\n",
        "            \n",
        "        Returns:\n",
        "            The predicted value.\n",
        "        \"\"\"\n",
        "        SK = np.dot(self.wt, X.transpose())\n",
        "        return SK\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vty76QCD5M6I"
      },
      "source": [
        "### Build the model and train on the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZUaTnq45M6J"
      },
      "outputs": [],
      "source": [
        "model = LinearRegression(0.001, 300000)\n",
        "model.train(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmwsyQJD5M6J"
      },
      "source": [
        "### (5 points) Implement the evaluation metric `mean squared error`.\n",
        "We use the [mean squared error (MSE)](https://en.wikipedia.org/wiki/Mean_squared_error) as the metric to evaluate our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJGitiGW5M6J"
      },
      "outputs": [],
      "source": [
        "def mean_squared_error(y_pred, y_actual):\n",
        "    \"\"\"\n",
        "    Calculates the mean squared error between two vectors.\n",
        "\n",
        "    Args:\n",
        "        y_pred: predicted values\n",
        "        y_actual: actual/true values\n",
        "\n",
        "    Returns:\n",
        "        The mean squared error.\n",
        "    \"\"\"\n",
        "   \n",
        "    MSE = np.sum(np.square(y_pred - y_actual))/len(y_actual)\n",
        "    return MSE\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WD5-HOza5M6K"
      },
      "source": [
        "### Make predictions using the model and evaluate it.\n",
        "If you have implemented `LinearRegression` correctly, the train MSE should be strictly lower that 0.5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GhM3B0e5M6K"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_train)\n",
        "print(\"Train MSE: {:.4f}\".format(mean_squared_error(y_pred, y_train)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OL41qsmo5M6K"
      },
      "source": [
        "### Plot the predicted and the actual values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8P2ZwkP5M6L"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(X_train, y_train, marker='X', label='actual')\n",
        "plt.scatter(X_train, y_pred, marker='o', label='predicted')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0JzgaKZ5M6L"
      },
      "source": [
        "### Multiple linear regression for sales prediction\n",
        "\n",
        "Next we use our linear regression model to learn the relationship between sales and advertising budget for a product. The `advertising.csv` dataset contains statistics about the sales of a product in 200 different markets, together with advertising budgets in each of these markets for different media channels: TV, radio, and newspaper. The sales are in thousands of units and the budget is in thousands of dollars.  \n",
        "\n",
        "We will train a linear regression model to predict the sales of the product given the TV, radio, and newspaper ad budgets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyyvWgdt5M6L"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('http://people.tamu.edu/~sumedhpendurkar/csce633/advertising.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDi9Q_CM5M6L"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9Ma4T2m5M6L"
      },
      "outputs": [],
      "source": [
        "X = np.array(df[['TV', 'Radio', 'Newspaper']])\n",
        "y = np.array(df['Sales'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WezTxIDX5M6M"
      },
      "source": [
        "### (5 points) Normalize the features in your dataset.\n",
        "\n",
        "Gradient descent-based models can be sensitive to different scales of the features/independent variables. Hence, it is important to normalize them. You may use the functions, `dataset_minmax`, `normalize_dataset`, and `unnormalize_dataset`, provided in the code block below to perform [min-max normalization](https://en.wikipedia.org/wiki/Feature_scaling) on the features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dk-widk5M6M"
      },
      "outputs": [],
      "source": [
        "def dataset_minmax(dataset):\n",
        "    \"\"\"\n",
        "    Finds the min and max values for each column.\n",
        "    \"\"\"\n",
        "    minmax = list()\n",
        "    for i in range(len(dataset[0])):\n",
        "        col_values = [row[i] for row in dataset]\n",
        "        value_min = min(col_values)\n",
        "        value_max = max(col_values)\n",
        "        minmax.append([value_min, value_max])\n",
        "    return minmax\n",
        "\n",
        "def normalize_dataset(dataset, minmax):\n",
        "    \"\"\"\n",
        "    Rescales dataset columns to the range 0-1.\n",
        "    \"\"\"\n",
        "    for row in dataset:\n",
        "        for i in range(len(row)):\n",
        "            row[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\n",
        "    return dataset\n",
        "\n",
        "def unnormalize_dataset(dataset, minmax):\n",
        "    \"\"\"\n",
        "    Rescales dataset columns to their original values.\n",
        "    \"\"\"\n",
        "    for row in dataset:\n",
        "        for i in range(len(row)):\n",
        "            row[i] = minmax[i][0] + (minmax[i][1] - minmax[i][0]) * row[i]\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "felwquMQ5M6M"
      },
      "outputs": [],
      "source": [
        "######################\n",
        "#   YOUR CODE HERE   #\n",
        "######################\n",
        "extremes = dataset_minmax(X)\n",
        "X = normalize_dataset(X, extremes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNtoduRZ5M6M"
      },
      "source": [
        "### Split the data into train and test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upbKlzhJ5M6M"
      },
      "outputs": [],
      "source": [
        "def split_indices(n, test_frac, seed):\n",
        "    \"\"\"\n",
        "    Provides indices for creating training and test set.\n",
        "    \"\"\"\n",
        "    # Determine the size of the test set\n",
        "    n_test = int(test_frac * n)\n",
        "    np.random.seed(seed)\n",
        "    # Create random permutation between 0 to n-1\n",
        "    idxs = np.random.permutation(n)\n",
        "    # Pick first n_test indices for test set\n",
        "    return idxs[n_test:], idxs[:n_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1anmKf05M6M"
      },
      "outputs": [],
      "source": [
        "test_frac = 0.2 ## Set the fraction for the test set\n",
        "rand_seed = 42 ## Set the random seed\n",
        "\n",
        "train_indices, test_indices = split_indices(df.shape[0], test_frac, rand_seed)\n",
        "print(\"#samples in training set: {}\".format(len(train_indices)))\n",
        "print(\"#samples in test set: {}\".format(len(test_indices)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LKL7HaY5M6N"
      },
      "outputs": [],
      "source": [
        "X_train = X[train_indices]\n",
        "y_train = y[train_indices]\n",
        "X_test = X[test_indices]\n",
        "y_test = y[test_indices]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTSYBGiv5M6N"
      },
      "source": [
        "### Build the model and train on the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHfl6AaO5M6N"
      },
      "outputs": [],
      "source": [
        "model = LinearRegression(0.01, 100000)\n",
        "model.train(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSOwSy8h5M6N"
      },
      "source": [
        "### (10 points) Evaluation on training and test set.\n",
        "If you have implemented `LinearRegression` correctly, the **test MSE** should be < 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moHF84P75M6N"
      },
      "outputs": [],
      "source": [
        "print(\"Training MSE: {:.4f}\".format(mean_squared_error(model.predict(X_train), y_train)))\n",
        "print(\"Test MSE: {:.4f}\".format(mean_squared_error(model.predict(X_test), y_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDK4lpdp5M6N"
      },
      "source": [
        "## Question 2 (50 points)\n",
        "\n",
        "## Logistic Regression\n",
        "\n",
        "In this section, we'll implement a logistic regression model that can learn to predict the class/label of a target/dependent variable based on multiple independent variables. We'll be using gradient descent to train the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leJVdC1z5M6N"
      },
      "source": [
        "### Data Preparation\n",
        "Once again, to keep things simple, first we'll use the heights and weights dataset to test our implementation. Let's divide the weights into 2 categories: -1 if the weight is < 60 and 1 otherwise. Our goal is to predict the weight category of an individual given their height using a logistic regression model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kiJNsv7Q5M6O"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('http://people.tamu.edu/~sumedhpendurkar/csce633/heights_weights.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_42bh8X5M6O"
      },
      "outputs": [],
      "source": [
        "X_train = np.array(df['Height'])\n",
        "y_train = np.array((df['Weight'] >= 60).astype('float'))\n",
        "y_train[y_train == 0] = -1\n",
        "X_train = np.expand_dims(X_train, -1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4HSmOQs5M6O"
      },
      "source": [
        "### (30 points) Implement the ` LogisticRegression` class\n",
        "Make sure it works with more than 1 feature.  \n",
        "**NOTE:** Do **NOT** forget to include a bias term in the weights. \n",
        "\n",
        "**NOTE:** Do **NOT** use closed form solutions. Use gradient descent to update weights\n",
        "\n",
        "**NOTE:** You can initalize your weights to 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKKO_ptt5M6O"
      },
      "outputs": [],
      "source": [
        "class LogisticRegression:   \n",
        "    def __init__(self, lr=0.001, epochs=30):\n",
        "        \"\"\"\n",
        "        Fits a logistic regression model on a given dataset.\n",
        "        \n",
        "        Args:\n",
        "            lr: learning rate \n",
        "            epochs: number of iterations over the dataset \n",
        "        \"\"\"\n",
        "        self.lr = lr  \n",
        "        self.epochs = epochs\n",
        "        self.wt = [55 for i in range(X_train.shape[1])]\n",
        "            \n",
        "        \n",
        "    # Function for model training         \n",
        "    def train(self, X, y):\n",
        "        \"\"\"\n",
        "        Initialize weights. Iterate through the dataset and update weights once every epoch.\n",
        "        \n",
        "        Args:\n",
        "            X: features\n",
        "            y: target\n",
        "        \"\"\"\n",
        "        for i in range(self.epochs):\n",
        "          self.update_weights(X, y)\n",
        "        \n",
        "         \n",
        "    def update_weights(self, X, y):\n",
        "        \"\"\"\n",
        "        Helper function to calculate the gradients and update weights in gradient descent.\n",
        "        \n",
        "        Args:\n",
        "            X: features\n",
        "            y: target\n",
        "        \"\"\"\n",
        "        GN = np.dot(np.dot(self.wt, X.transpose()), y.transpose())\n",
        "        Sigma = 1 / (1 + np.exp(-GN))\n",
        "        Sigma2 = Sigma - 1\n",
        "        y = np.expand_dims(y, -1)\n",
        "        dl = np.sum(Sigma2 * X * y, axis = 0)\n",
        "        self.wt -= self.lr * dl\n",
        "        \n",
        "     \n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predict probabilities using the weights.\n",
        "        \n",
        "        Args:\n",
        "            X: features\n",
        "            \n",
        "        Returns:\n",
        "            The predicted probability.\n",
        "        \"\"\"\n",
        "        Q = []\n",
        "        KN = np.dot(X, self.wt.transpose())\n",
        "        Q = 1 / (1 + np.exp(-KN))\n",
        "        return Q\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLmAoKGr5M6O"
      },
      "source": [
        "### Build the model and train on the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Ci-HwER5M6O"
      },
      "outputs": [],
      "source": [
        "model = LogisticRegression(0.01, 100000)\n",
        "model.train(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpCUUNEu5M6P"
      },
      "source": [
        "### (5 points) Implement the evaluation metric `accuracy`.\n",
        "We use the [accuracy](https://developers.google.com/machine-learning/crash-course/classification/accuracy) as the metric to evaluate our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OK04lL0o5M6P"
      },
      "outputs": [],
      "source": [
        "def accuracy(y_pred, y_actual):\n",
        "    \"\"\"\n",
        "    Calculates the accuracy of the predictions (binary values).\n",
        "\n",
        "    Args:\n",
        "        y_pred: predicted values\n",
        "        y_actual: actual/true values\n",
        "\n",
        "    Returns:\n",
        "        The accuracy.\n",
        "    \"\"\"\n",
        "    GPA = 0\n",
        "    for i in range(y_pred.shape[0]):\n",
        "      if y_pred[i] == y_actual[i]:\n",
        "        GPA += 1\n",
        "    return (GPA / y_pred.shape[0])\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EL8s9n75M6P"
      },
      "source": [
        "### Make predictions using the model and evaluate it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4CWVD8w5M6P"
      },
      "outputs": [],
      "source": [
        "y_pred_probs = model.predict(X_train)\n",
        "y_pred = np.copy(y_pred_probs)\n",
        "y_pred[y_pred > 0] = 1\n",
        "y_pred[y_pred <= 0] = -1\n",
        "print(\"Train Accuracy: {}\".format(accuracy(y_pred, y_train)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "159LkP775M6P"
      },
      "source": [
        "### Plot the predicted and the actual values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NM41j1ob5M6P"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(X_train, y_train, marker='x', label='actual', alpha=1)\n",
        "plt.scatter(X_train, y_pred, marker='o', label='predicted', alpha=0.6)\n",
        "plt.scatter(X_train, y_pred_probs, marker='o', label='predicted probabilities', alpha=0.7)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNHbjs_c5M6P"
      },
      "source": [
        "### Multiple logistic regression to identify forged banknotes.\n",
        "\n",
        "Next we train our logistic regression model to identify forged banknotes. The `banknote_authentication.csv` dataset has been created from images that were taken from genuine and forged banknote-like specimens. For digitization, an industrial camera usually used for print inspection was used. The final images have 400x400 pixels. Due to the object lens and distance to the investigated object gray-scale pictures with a resolution of about 660 dpi were gained. Wavelet Transform tool were used to extract features from images.  \n",
        "\n",
        "We will train a logistic regression model to distinguish between genuine and forged banknotes given features extarcted from their images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUAJsVFv5M6Q"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('http://people.tamu.edu/~sumedhpendurkar/csce633/banknote_authentication.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZO8UwxXh5M6Q"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFQShz_Q5M6Q"
      },
      "outputs": [],
      "source": [
        "X = np.array(df[['variance', 'skewness', 'curtosis', 'entropy']])\n",
        "y = np.array(df['class'])\n",
        "y[y == 0] = -1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQxt0xWm5M6Q"
      },
      "source": [
        "### (5 points) Normalize the features in your dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVpnpqoQ5M6Q"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPIRLgVe5M6Q"
      },
      "source": [
        "### Split the data into train and test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hN6POA1z5M6Q"
      },
      "outputs": [],
      "source": [
        "test_frac = 0.143 ## Set the fraction for the validation set\n",
        "rand_seed = 55 ## Set the random seed\n",
        "\n",
        "train_indices, test_indices = split_indices(df.shape[0], test_frac, rand_seed)\n",
        "print(\"#samples in training set: {}\".format(len(train_indices)))\n",
        "print(\"#samples in test set: {}\".format(len(test_indices)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSCxxV0V5M6Q"
      },
      "outputs": [],
      "source": [
        "X_train = X[train_indices]\n",
        "y_train = y[train_indices]\n",
        "X_test = X[test_indices]\n",
        "y_test = y[test_indices]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mcmhsez5M6Q"
      },
      "source": [
        "### Build the model and train on the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ko4kEDwq5M6R"
      },
      "outputs": [],
      "source": [
        "model = LogisticRegression(0.1, 10000)\n",
        "model.train(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7z7GhuhR5M6R"
      },
      "source": [
        "### (10 points) Evaluation on training and test set.\n",
        "If you have implemented `LogisticRegression` correctly, the **test accuracy** should be > 0.92."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFtScHCY5M6R"
      },
      "outputs": [],
      "source": [
        "y_pred_probs = model.predict(X_train)\n",
        "y_pred = np.copy(y_pred_probs)\n",
        "y_pred[y_pred > 0] = 1\n",
        "y_pred[y_pred <= 0] = -1\n",
        "print(\"Train Accuracy: {:.4f}\".format(accuracy(y_pred, y_train)))\n",
        "y_pred_probs = model.predict(X_test)\n",
        "y_pred = np.copy(y_pred_probs)\n",
        "y_pred[y_pred > 0] = 1\n",
        "y_pred[y_pred <= 0] = -1\n",
        "print(\"Test Accuracy: {:.4f}\".format(accuracy(y_pred, y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CrFr6OpK5M6R"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    },
    "colab": {
      "name": "pa2-linear-and-logistic-regression.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "wTSYBGiv5M6N",
        "gSOwSy8h5M6N",
        "QLmAoKGr5M6O",
        "zpCUUNEu5M6P",
        "NQxt0xWm5M6Q",
        "fPIRLgVe5M6Q",
        "2mcmhsez5M6Q"
      ]
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}